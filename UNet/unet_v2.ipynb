{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model Implementation\n",
    "Environment Notebook was built in:\n",
    "- Google Colab\n",
    "\n",
    "Hardware needs:\n",
    "- 10 GB CPU RAM\n",
    "- NVidia T4 GPU -> 16 GB\n",
    "- 30 GB disk\n",
    "\n",
    "## Data Gathering and Augmentation\n",
    "\n",
    "### Imports and Installs\n",
    "\n",
    "#### Using detect_model_requirements.txt\n",
    "- Please uncomment to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to create notebook package requirments file called segment_model_requirements.txt\n",
    "# !pip freeze > segment_model_requirements.txt\n",
    "\n",
    "# use the code below to use detect_model_requirements.txt to install all necessary packages\n",
    "#!pip install -r segment_model_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neccessary installs on top of Google Colab environment\n",
    "- Uncomment to run this cell if you aren't using segment_model_requirements.txt and are operating in the GPU google colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-cloud-storage\n",
    "#!pip install pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Library Imports\n",
    "import os\n",
    "import time\n",
    "from io import BytesIO\n",
    "import random\n",
    "\n",
    "#Third party imports\n",
    "from google.cloud import storage\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.functional import pad\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import ipyplot\n",
    "\n",
    "import altair\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#Local application imports\n",
    "from transforms import (\n",
    "    ComposeDouble,\n",
    "    FunctionWrapperDouble,\n",
    "    create_dense_target,\n",
    "    normalize,\n",
    "    gaussian_smoothing,\n",
    "    image_histogram_equalization\n",
    ")\n",
    "\n",
    "import build_unet\n",
    "\n",
    "from helper import (\n",
    "    dice_loss,\n",
    "    custom_collate,\n",
    "    analyze_num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing data from Google bucket\n",
    "First, we want to set up credentials and the client. The Waymo dataset isn't publicly open for use without permissions. Permissions were required for transfer of bucket information from Waymo google cloud services to our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_store = 'GCS' # kindly use either 'GCS' for Google cloud storage or 'LOCAL' for files stored in the same folder as notebook\n",
    "\n",
    "# leave both as None if using LOCAL or replace this with your GCS api key json file and Bucket name\n",
    "google_application_credentials = '/content/authentication.json' #replace this string with your own credentials\n",
    "bucket_name = 'waymo_sample_bucket'\n",
    "\n",
    "if file_store == 'GSC':\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = google_application_credentials\n",
    "    client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading from the bucket\n",
    "For smaller numbers of parquets, a dataframe is created all at once. \n",
    "\n",
    "Otherwise, for the larger, overall training, we iteratively download parquet information. The functions below do these things. This is to ensure memory ease.\n",
    "\n",
    "- Camera Image Parquet Files\n",
    "- Camera Segmentation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab data for iterative training\n",
    "def grab_data_image():\n",
    "  # Get the bucket and list the blobs with the specified prefix (folder name)\n",
    "  df_temp = pd.DataFrame()\n",
    "  bucket = client.get_bucket(bucket_name)\n",
    "  blobs_image = list(bucket.list_blobs(prefix='training/camera_image/'))\n",
    "\n",
    "  for blob1 in blobs_image:\n",
    "    object_name_image = blob1.name[len('training/camera_image/'):]\n",
    "\n",
    "    print(\"Loading in \", blob1)\n",
    "\n",
    "    temp = \"temp_file.parquet\"\n",
    "    #download the blob content to a temp file\n",
    "    blob1.download_to_filename(temp)\n",
    "    df = pd.read_parquet(temp)\n",
    "  \n",
    "    #Yield results for iterative training  \n",
    "    yield df\n",
    "\n",
    "# Grab data for iterative training\n",
    "def grab_data_segment():\n",
    "  # Get the bucket and list the blobs with the specified prefix (folder name)\n",
    "  df_temp = pd.DataFrame()\n",
    "  bucket = client.get_bucket(bucket_name)\n",
    "  blobs_segment = list(bucket.list_blobs(prefix='training/camera_segmentation/'))\n",
    "\n",
    "  for blob2 in blobs_segment:\n",
    "    object_name = blob2.name[len('training/camera_segmentation/'):]\n",
    "\n",
    "    print(\"Loading in \", blob2)\n",
    "\n",
    "    temp = \"temp_file.parquet\"\n",
    "    #download the blob content to a temp file\n",
    "    blob2.download_to_filename(temp)\n",
    "    df = pd.read_parquet(temp)\n",
    "    \n",
    "    #Yield results for iterative training  \n",
    "    yield df\n",
    "\n",
    "#--------This one will be important for hyperparameter tuning ---------\n",
    "def grab_data(folder_name = 'training/camera_image/', max_parquet = 3):\n",
    "\n",
    "  # Get the bucket and list the blobs with the specified prefix (folder name)\n",
    "  df_temp = pd.DataFrame()\n",
    "  bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "  blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "  #random.Random(random_seed).shuffle(blobs)\n",
    "  i = -1\n",
    "  for blob in blobs:\n",
    "    i += 1\n",
    "    object_name = blob.name[len(folder_name):]\n",
    "    temp = \"temp_file.parquet\"\n",
    "    #download the blob content to a temp file\n",
    "    blob.download_to_filename(temp)\n",
    "    df = pd.read_parquet(temp)\n",
    "    if df_temp.empty:\n",
    "      df_temp = df\n",
    "    else:\n",
    "      df_temp = pd.concat([df_temp,df])\n",
    "    if i == max_parquet :\n",
    "      break\n",
    "\n",
    "  return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Local use\n",
    "- get_local_data is a one and go use, particulary for the hyperparameter tuning. This is best for the sample data.\n",
    "- This example is best used for the sample data and fits the similar format.\n",
    "\n",
    "- The other two functions are data generators for iterative training of the larger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_data():\n",
    "    ''''\n",
    "    The one-and-go for sample images for hyperparameter tuning\n",
    "    ''''\n",
    "    camera_image_file_path = 'waymo_sample_data/training/camera_image'\n",
    "    segmented_image_file_path = 'waymo_sample_data/training/camera_segmentation'\n",
    "    camera_images = os.listdir(camera_image_file_path)\n",
    "    segmented_images = os.listdir(segmented_image_file_path)\n",
    "\n",
    "    # Get local camera image data\n",
    "    df_temp_camera = pd.DataFrame()\n",
    "    for each in camera_images:\n",
    "        temp_parquet_file_path = camera_image_file_path + \"/\" + each\n",
    "        df = pd.read_parquet(temp_parquet_file_path)\n",
    "        if df_temp_camera.empty:\n",
    "            df_temp_camera = df\n",
    "        else:\n",
    "            df_temp_camera = pd.concat([df_temp_camera,df])\n",
    "\n",
    "    # Get local segmented image data\n",
    "    df_temp_seg = pd.DataFrame()\n",
    "    for each in segmented_images_images:\n",
    "        temp_parquet_file_path = segmented_image_file_path + \"/\" + each\n",
    "        df = pd.read_parquet(temp_parquet_file_path)\n",
    "        if df_temp_seg.empty:\n",
    "            df_temp_seg = df\n",
    "        else:\n",
    "            df_temp_seg= pd.concat([df_temp_seg,df])\n",
    "\n",
    "    # The merged dataframe\n",
    "    df_tot = pd.merge(df_temp_camera,df_temp_seg,on=['key.segment_context_name','key.frame_timestamp_micros','key.camera_name'])[['[CameraImageComponent].image','[CameraSegmentationLabelComponent].panoptic_label']]\n",
    "\n",
    "    print(\"There are\" , len(df_tot) ,\"images\") #checking the results of the merge\n",
    "    df_tot.columns = ['image','seg_label'] #rename columns for typing ease\n",
    "    return df_tot\n",
    "\n",
    "\n",
    "def camera_images():\n",
    "    camera_images = os.listdir('waymo_sample_data/training/camera_image')\n",
    "    # Get local camera image data\n",
    "    for each in camera_images:\n",
    "        df = pd.read_parquet(\"waymo_sample_data/training/camera_image/\" + each)\n",
    "        yield df\n",
    "\n",
    "def segmented_images():\n",
    "    segmented_images = os.listdir('waymo_sample_data/training/camera_segmentation')\n",
    "    # Get local segmented image data\n",
    "    for each in segmented_images:\n",
    "        df = pd.read_parquet(\"waymo_sample_data/training/camera_segmentation/\" + each)\n",
    "        yield df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Data\n",
    "Firstly, we want to define a class that allows us to transform out current data into a pytorch related format, configured with transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataSet(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 inputs: list,\n",
    "                 targets: list,\n",
    "                 transform=None\n",
    "                 ):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.inputs_dtype = torch.float32\n",
    "        self.targets_dtype = torch.long\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,\n",
    "                    index: int):\n",
    "        # Select the sample\n",
    "        input_ID = self.inputs[index]\n",
    "        target_ID = self.targets[index]\n",
    "\n",
    "        # Load input and target\n",
    "        x = np.array(Image.open(BytesIO(input_ID)))\n",
    "        y = np.array(Image.open(BytesIO(target_ID)))\n",
    "\n",
    "        # Preprocessing\n",
    "        if self.transform is not None:\n",
    "            x, y = self.transform(x, y)\n",
    "\n",
    "        # Typecasting\n",
    "        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)\n",
    "\n",
    "        return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply a pipeline of transformations to the training data. This is to help prevent data leakage, as well as streamline our process. We resize the images to be smaller in order to prevent any memory issues when developing our model. Due the size of our dataset and varying images previewed, we decided against further augmentation of the data. \n",
    "Augmentation would be considered if the original dataset were smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "transforms = ComposeDouble([\n",
    "    #Turn to grayscale\n",
    "    FunctionWrapperDouble(skimage.color.rgb2gray,input=True,target=False),\n",
    "    #Resizing\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=True,\n",
    "                          target=False,\n",
    "                          output_shape=(640, 960),\n",
    "                          anti_aliasing=True,\n",
    "                          preserve_range=True),\n",
    "    FunctionWrapperDouble(resize,\n",
    "                          input=False,\n",
    "                          target=True,\n",
    "                          output_shape=(640, 960),\n",
    "                          order=0,\n",
    "                          anti_aliasing=False,\n",
    "                          preserve_range=True),\n",
    "\n",
    "    # Normalizing\n",
    "    FunctionWrapperDouble(normalize,input=True,target=False),\n",
    "\n",
    "    # Smooth it out \n",
    "    FunctionWrapperDouble(gaussian_smoothing, input=True, target=False, sigma_val=1),\n",
    "\n",
    "    # Contrast enhancement - using histogram equalization\n",
    "    FunctionWrapperDouble(image_histogram_equalization,input=True,target=False),\n",
    "    \n",
    "    # Ensure target segmented images are dense\n",
    "    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The big Hyperparameter tuning loop!\n",
    "This loop is configured to save the loss and validation outputs from each run in order to later be analyzed. We are grabbing the data differently here then we are in the actual training. Due to the smaller nature of the hyperparameter tuning, we are going to load the data beforehand before applying. Here we are gathering about 200 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_store == \"GSC\":\n",
    "    #--------- Get image data ------------\n",
    "    df_image = grab_data(folder_name= 'training/camera_image/', max_parquet = 3)\n",
    "\n",
    "    # --------- Get segmented data ----------\n",
    "    df_seg = grab_data(folder_name= 'training/camera_segmentation/', max_parquet = 3)\n",
    "\n",
    "    # The merged dataframe\n",
    "    df_tot = pd.merge(df_image,df_seg,on=['key.segment_context_name','key.frame_timestamp_micros','key.camera_name'])[['[CameraImageComponent].image','[CameraSegmentationLabelComponent].panoptic_label']]\n",
    "    df_tot = df_tot.sample(200, ignore_index=True)\n",
    "\n",
    "    print(\"There are\" , len(df_tot) ,\"images\") #checking the results of the merge\n",
    "    df_tot.columns = ['image','seg_label'] #rename columns for typing ease\n",
    "\n",
    "    # Help clear up some space\n",
    "    del df_image\n",
    "    del df_seg\n",
    "elif file_store == \"LOCAL\":\n",
    "    df_tot = get_local_data()\n",
    "else:\n",
    "    print(\"Check file_store variable, it is CASE sensitive. Options are GSC or LOCAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some loss functions and other hyperparameters to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions you want to try\n",
    "loss_functions = {\n",
    "    \"DiceLoss\" : dice_loss,\n",
    "    \"CrossEntropyLoss\": nn.CrossEntropyLoss(),\n",
    "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss(),\n",
    "}\n",
    "\n",
    "# Define different hyperparameter settings to try\n",
    "hyperparameters = {\n",
    "    \"lr\": [0.0001,0.001],\n",
    "    \"batch_size\": [2,6,12],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SegmentationDataSet(inputs=df_tot['image'],\n",
    "                                       targets=df_tot['seg_label'],\n",
    "                                       transform=transforms)\n",
    "n_val = int(len(dataset) * 0.1)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, we Tune! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "best_loss = float(\"inf\")\n",
    "best_loss_function = None\n",
    "best_hyperparameters = None\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "results = []\n",
    "\n",
    "# Loop for Loss functions\n",
    "for loss_name, loss_function in loss_functions.items():\n",
    "  # Loop for Learning Rate\n",
    "  for lr in hyperparameters[\"lr\"]:\n",
    "    # Loop for Batch Size\n",
    "    for batch_size in hyperparameters[\"batch_size\"]:\n",
    "      # Now we're running!\n",
    "      print(\"Running \"+loss_name+\" with loss rate of \",lr,\"with batch size\",batch_size)\n",
    "\n",
    "      # put the training and validation data into each dataloader\n",
    "      training_dataloader = data.DataLoader(dataset=train_set,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "      validation_dataloader = data.DataLoader(dataset=val_set,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "\n",
    "      # Create our model instance, optimizer, and loss function\n",
    "      model = build_unet(num_classes=1, device=device).to(device)\n",
    "      optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "      criterion = loss_function\n",
    "\n",
    "      # Initialize the GradScaler for mixed-precision training\n",
    "      scaler = GradScaler()\n",
    "\n",
    "      loss_per_epoch = []\n",
    "      #Epoch Loop\n",
    "      for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, (inputs, labels, mask) in enumerate(training_dataloader):\n",
    "\n",
    "          # Move inputs and labels to the GPU\n",
    "          if device.type == 'cuda':\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            mask = mask.to(device, dtype=torch.float32)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Analyze the number of classes in the current segmentation mask\n",
    "          num_classes = analyze_num_classes(labels)\n",
    "\n",
    "          # Update the model's output layer to have the correct number of channels (classes)\n",
    "          model.output_layer = nn.Conv2d(64, num_classes, kernel_size=1, padding=0)\n",
    "\n",
    "          # Add nn.Parameter for bias with the desired precision\n",
    "          model.output_layer.bias = nn.Parameter(torch.zeros(num_classes, dtype=torch.float32, device=device))\n",
    "\n",
    "          # Use autocast to perform mixed-precision training\n",
    "          with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs*mask, labels*mask)\n",
    "            #loss_per_epoch.append(loss.item())\n",
    "\n",
    "          scaler.scale(loss).backward()\n",
    "          scaler.step(optimizer)\n",
    "          scaler.update()\n",
    "\n",
    "          total_loss += loss.item()\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        average_loss = total_loss / len(training_dataloader)\n",
    "        loss_per_epoch.append(average_loss)\n",
    "        # End time for the epoch\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        #Print progress with batch and epoch times\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "        ## ------------ end of current epoch ---------------\n",
    "\n",
    "        ## - ----------- eval ------------------------------\n",
    "        model.eval() # set to eval mode\n",
    "        total_val_loss = 0.0\n",
    "        eval_loss_list = []\n",
    "        with torch.no_grad():\n",
    "          for val_batch_idx, (val_inputs, val_labels,val_mask) in enumerate(validation_dataloader):\n",
    "            # Move validation inputs and labels to the same device as the model\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_mask = val_mask.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            val_outputs = model(val_inputs)\n",
    "\n",
    "            #Compute the validation loss\n",
    "            if loss_name == 'CrossEntropyLoss':\n",
    "              val_labels_indices = (val_labels*val_mask).argmax(dim=1)\n",
    "              val_loss = criterion(val_outputs*val_mask, val_labels_indices)\n",
    "            else:\n",
    "              val_loss = criterion(val_outputs*val_mask, val_labels*val_mask)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "        # Calculate the average validation loss\n",
    "        average_val_loss = total_val_loss / len(validation_dataloader)\n",
    "        eval_loss_list.append(average_val_loss)\n",
    "        print(f\"Validation Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "      # Update best hyperparameters if current loss is better\n",
    "      if average_loss < best_loss and average_loss >= 0: #we don't want super big negatives\n",
    "        best_loss = average_loss\n",
    "        best_loss_function = loss_name\n",
    "        best_hyperparameters = {\"lr\": lr, \"batch_size\": batch_size}\n",
    "\n",
    "      # Save hyperparameter tuning information and loss\n",
    "      result = {\n",
    "          \"Loss Function\": loss_name,\n",
    "          \"Learning Rate\": lr,\n",
    "          \"Batch Size\": batch_size,\n",
    "          \"Loss per Epoch\": loss_per_epoch,\n",
    "          \"Validation Loss per Epoch\": eval_loss_list\n",
    "      }\n",
    "      results.append(result)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results) #Import for visualizations\n",
    "print(f\"Best loss function: {best_loss_function}\")\n",
    "print(f\"Best hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you want to save?\n",
    "Uncomment the below portion to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Saving all of Information\")\n",
    "# results_df.to_csv(\"hyperparam_tuning.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, we graph\n",
    "Graphing with Altair involves configuring our results dataframe a little bit before going ahead and applying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = []\n",
    "for _ in results_df['Loss per Epoch']:\n",
    "  epoch_num.append(range(num_epochs))\n",
    "\n",
    "results_df['Epoch_Num'] = epoch_num\n",
    "\n",
    "results_df = results_df.explode(['Loss per Epoch','Epoch_Num']).reset_index(drop=True)\n",
    "\n",
    "alt.Chart(results_df).mark_line().encode(\n",
    "    x = 'Epoch_Num:N',\n",
    "    y = 'Loss per Epoch:Q',\n",
    "    color = 'Batch Size:N',\n",
    ").properties(\n",
    "    width = 180,\n",
    "    height = 180\n",
    ").facet(\n",
    "    column ='Loss Function:N',\n",
    "    row ='Learning Rate:N'\n",
    ").resolve_scale(\n",
    "    y = 'independent',\n",
    "    x = 'independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to Train\n",
    "- Training requires the input data to be in the format of a generator!\n",
    "- The number of parquets defined is the number provided in the sample. \n",
    "\n",
    "Firstly, we want to define the use of GPU as well as our preferred hyperparameters. The GPU was set in our hyperparameter tuning loop, but it doesn't hurt to double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to run off of GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Set hyperparameters\n",
    "hyperparameters = {\n",
    "    'lr': 0.0001,\n",
    "    'batch_size': 6,\n",
    "    'loss_function': dice_loss,\n",
    "    'parquets': 2, \n",
    "    'num_epochs' : 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the model instance and train as followed, iteratively going through each parquet file from the WAYMO perception bucket.\n",
    "Checkpoints are built in and print statements so that in case something occurs, the current model state is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the model\n",
    "model = build_unet(num_classes=1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay = 0.01)\n",
    "criterion = hyperparameters['loss_function']\n",
    "\n",
    "# Initialize the GradScaler for mixed-precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Initialize the data generators to iterate through\n",
    "if local_store == 'GSC':\n",
    "    df_image = grab_data_image()\n",
    "    df_seg = grab_data_segment()\n",
    "elif local_store == \"LOCAL\":\n",
    "    df_image = camera_images()\n",
    "    df_seg = segmented_images()\n",
    "    \n",
    "\n",
    "# to hold our results\n",
    "results = []\n",
    "\n",
    "i = 0\n",
    "# Iterating through data\n",
    "while i < hyperparameters['parquets']:\n",
    "    i += 1\n",
    "\n",
    "    print(\"Loaded parquet\",i)\n",
    "    # The merged dataframe\n",
    "    df_tot = pd.merge(next(df_image),next(df_seg),on=['key.segment_context_name','key.frame_timestamp_micros','key.camera_name'])[['[CameraImageComponent].image','[CameraSegmentationLabelComponent].panoptic_label']]\n",
    "\n",
    "    print(\"Iteration\",i,\"There are\" , len(df_tot) ,\"images\") #checking the results of the merge\n",
    "    df_tot.columns = ['image','seg_label'] #rename columns for typing ease\n",
    "\n",
    "    training_dataset = SegmentationDataSet(inputs=df_tot['image'],\n",
    "                                       targets=df_tot['seg_label'],\n",
    "                                       transform=transforms)\n",
    "    ## ----- Training loop -----------\n",
    "    training_dataloader = data.DataLoader(dataset=training_dataset,\n",
    "                                      batch_size=hyperparameters['batch_size'],\n",
    "                                      shuffle=True,\n",
    "                                      collate_fn = custom_collate\n",
    "                                      )\n",
    "\n",
    "    loss_per_epoch = []\n",
    "    for epoch in range(hyperparameters['num_epochs']):\n",
    "        loss_per_epoch = []\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (inputs, labels, mask) in enumerate(training_dataloader):\n",
    "            \n",
    "            # Move inputs and labels to the GPU\n",
    "            if device.type == 'cuda':\n",
    "                inputs = inputs.to(device, dtype=torch.float32)\n",
    "                labels = labels.to(device, dtype=torch.float32)\n",
    "                mask = mask.to(device, dtype=torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Analyze the number of classes in the current segmentation mask\n",
    "            num_classes = analyze_num_classes(labels)\n",
    "            # Update the model's output layer to have the correct number of channels (classes)\n",
    "            model.output_layer = nn.Conv2d(64, num_classes, kernel_size=1, padding=0)\n",
    "            # Add nn.Parameter for bias with the desired precision\n",
    "            model.output_layer.bias = nn.Parameter(torch.zeros(num_classes, dtype=torch.float32, device=device))\n",
    "\n",
    "            # Use autocast to perform mixed-precision training\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.to(outputs.dtype)\n",
    "                loss = criterion(outputs*mask, labels*mask)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        # Calculate average loss for the epoch\n",
    "        average_loss = total_loss / len(training_dataloader)\n",
    "        loss_per_epoch.append(average_loss)\n",
    "        # End time for the epoch\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        #Print progress with batch and epoch times\n",
    "        print(f\"Epoch [{epoch + 1}/{hyperparameters['num_epochs']}], Loss: {average_loss:.4f}, Epoch Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    result = {\n",
    "        \"Loss per Epoch\": loss_per_epoch\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "    checkpoint = {\n",
    "        'Parquet':i,\n",
    "        'model_state_dict':model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss' : loss_per_epoch\n",
    "    }\n",
    "    checkpoint_path = f'checkpoint_iteration_{i}.pth'\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f'Checkpoint saved at iteration {i}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is all good and done, we go ahead and save our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'unet_model_waymo.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaing our Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df = df.reset_index()\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x = alt.X('index:N',title='Parquet Iteration'),\n",
    "    y = alt.Y('Loss per Epoch:Q',title=\"Average Loss\"),\n",
    ").properties(\n",
    "    title='Average Loss During U-Net Training'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
