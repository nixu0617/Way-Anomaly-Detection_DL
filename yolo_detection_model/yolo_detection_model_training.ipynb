{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MapleWolfe/Anomaly_detection_waymo_open/blob/main/yolo_detection_model/yolo_detection_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25GdaRiEvePn"
      },
      "source": [
        "# Building Model for Waymo open dataset\n",
        "- please see the detection_model_readme.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Enviornment Notebook was built in:\n",
        "- Kindly run this notebook in Google Colab\n",
        "\n",
        "##### Hardware needs:\n",
        "\n",
        "- Kindly use a minimum of 12 GB CPU ram\n",
        "- the standard Nvidia T4 GPU that comes with the free version of Google Colab.\n",
        "- 50 GB disk Minimum (less should work but this was the minimum during notebook creation)\n",
        "\n",
        "##### following files should be in local directory if using the local notebook\n",
        "- these files should be in the same folder as notebook\n",
        "\n",
        "##### instructions to run notebook,\n",
        "- Kindly fill in the code cell below to use the local parquet files stored in the same folder as notebook or the parquet files stored in a GCS bucket"
      ],
      "metadata": {
        "id": "d-VVlaMJ_S4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do you want to use local sample files or google cloud storage?\n",
        "file_store = 'GCS' # kindly use either 'GCS' for Google cloud storage or 'LOCAL' for files stored in the same folder as notebook\n",
        "\n",
        "# leave both as None if using LOCAL or kindly replace this with your GCS api key json file and Bucket name or else\n",
        "gcs_json_key = 'put_google_json_key.json' # please remember to start file path here with '/content/' + your json key file name\n",
        "bucket_name = 'waymo_sample_bucket' # remember to replace this\n",
        "\n",
        "#these are the file download limits for hyper param tuning, it limits the number of parquet files being downloaded for training / validation / test\n",
        "train_limit = 2 #-1 means all relevant files in your google bucket\n",
        "val_limit = 1 #-1 means all relevant files in your google bucket\n",
        "test_limit = 1 #-1 means all relevant files in your google bucket\n",
        "\n",
        "final_model_train_limit = 40 #-1 means all relevant files in your google bucket\n",
        "\n",
        "# the path below is to the sample files: there are 4 parquets in total, you just need to upload the waymo_sample_data folder from github repo\n",
        "train_box_data_file_path  = 'waymo_sample_data/training/camera_box/training_camera_box_10017090168044687777_6380_000_6400_000.parquet'\n",
        "train_image_data_file_path = 'waymo_sample_data/training/camera_image/training_camera_image_10017090168044687777_6380_000_6400_000.parquet'\n",
        "val_box_data_file_path = 'waymo_sample_data/validation/camera_box/validation_camera_box_10203656353524179475_7625_000_7645_000.parquet'\n",
        "val_image_data_file_path = 'waymo_sample_data/validation/camera_image/validation_camera_image_10203656353524179475_7625_000_7645_000.parquet'\n",
        "\n",
        "# this is the yaml file that provides data structure, please input it from the github repository\n",
        "yaml_file = 'yolov8_waymo.yaml'"
      ],
      "metadata": {
        "id": "TLmtrOPvfAgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1efbiYyBwl5V"
      },
      "source": [
        "## installs, imports, pre-sets\n",
        "\n",
        "- kindly open and run cell blocks based on the enviornment being run in to save computational resources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using detect_model_requirements.txt\n",
        "- please uncomment to use"
      ],
      "metadata": {
        "id": "4TZffgE6--bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment to create notebook package requirments file called detect_model_requirements.txt\n",
        "# !pip freeze > detect_model_requirements.txt\n",
        "\n",
        "# use the code below to use detect_model_requirements.txt to install all necessary packages\n",
        "#!pip install -r detect_model_requirements.txt"
      ],
      "metadata": {
        "id": "AEw4lY1k8_EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neccessary installs on top of google colab\n",
        "- uncomment and Run this cell if you aren't using detect_model_requirements.txt and are operating in the GPU google colab enviornment"
      ],
      "metadata": {
        "id": "EXuACyZEEya7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvf-dj0GvdxW"
      },
      "outputs": [],
      "source": [
        "#!pip install google-cloud-storage\n",
        "#!pip install ultralytics\n",
        "#!pip install altair"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "BuxoPuoiHKka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrS7BbTI8vEQ"
      },
      "outputs": [],
      "source": [
        "# installs for google cloud storage\n",
        "from google.cloud import storage\n",
        "\n",
        "# general tool installs\n",
        "import os, io, shutil, warnings\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "#image processing and plotting libraries\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import altair as alt\n",
        "\n",
        "# data processing librarires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# model evaluation\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# model libraries\n",
        "import tensorflow as tf\n",
        "from ultralytics import YOLO\n",
        "\n",
        "#pre-sets\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utility functions\n",
        "- functions that may be used at a later point"
      ],
      "metadata": {
        "id": "qE6iWVWNq0md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### delete file function"
      ],
      "metadata": {
        "id": "GO9cCRwqq9G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to delete a file\n",
        "def delete_file(file_path_list):\n",
        "  for a_file in (file_path_list):\n",
        "    os.remove(a_file)\n",
        "  return None"
      ],
      "metadata": {
        "id": "neffr318q_Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### move copy function"
      ],
      "metadata": {
        "id": "KQOjtFvRR3rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_copy(old_location, new_location):\n",
        "  shutil.copy(old_location, new_location)\n",
        "  return None"
      ],
      "metadata": {
        "id": "-wXmxJz8R87z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### download blob function"
      ],
      "metadata": {
        "id": "QGybKhahuvLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to download a blob file\n",
        "def download_blob(a_blob,file_name):\n",
        "  a_blob.download_to_filename(file_name)\n",
        "  return None"
      ],
      "metadata": {
        "id": "0EXbcuJcuzq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's create folder directory for YOLO\n",
        "- built as per .yaml file"
      ],
      "metadata": {
        "id": "JwM9qp-8tTl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#folder name list for directory\n",
        "def make_directory(folder_name_list):\n",
        "  folder_path = os.path.join(*folder_name_list)\n",
        "  if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "  return None\n",
        "\n",
        "#function to build yolo directory structure\n",
        "def build_yolo_directory():\n",
        "  for folder_type in ['train','test','eval']:\n",
        "    for data_type in ['images', 'labels']:\n",
        "      make_directory(['datasets',folder_type,data_type])\n",
        "  return None\n",
        "\n"
      ],
      "metadata": {
        "id": "wPeKxiYvtMXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# running directory function\n",
        "build_yolo_directory()"
      ],
      "metadata": {
        "id": "xDggpi2_voCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnpY5qVHuE9x"
      },
      "source": [
        "## Google Cloud Storage section\n",
        "\n",
        "- Run these cells if you are using your private google cloud storage.\n",
        "- kindly ensure that your bucket has the same structure and file names as the waymo_open_dataset_v_2_0_0 bucket"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def start_gcs(gcs_json_key = gcs_json_key, bucket_name = bucket_name):\n",
        "# Please input API JSON KEY FOR your private google cloud storage where the files are kept in gcs_json_key defined in the first codeblock\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = gcs_json_key\n",
        "    client = storage.Client()\n",
        "# replace the bucket name with the bucket name in your GCS, use the bucket_name object  in the first codeblock\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "#getting file list\n",
        "    files = bucket.list_blobs()\n",
        "    files_list = [a_file.name for a_file in files]\n",
        "    return bucket, files_list\n"
      ],
      "metadata": {
        "id": "PRZeQG2scdL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCS Iterative File Dowload function\n",
        "(Bare Image parquet and Bounding box parquet files)"
      ],
      "metadata": {
        "id": "EeMf3LBtorBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi1hP1Hbs7sB"
      },
      "outputs": [],
      "source": [
        "# in the following function we are creating blobs: one blob object for images parquet and another blob for box coordinates parquet\n",
        "def open_gcs_file(files_list,bucket, storage_folder = 'training'):\n",
        "    # lets ensure that we have the correct file type\n",
        "    if storage_folder not in ['training','testing','validation']:\n",
        "      print('''please retype storage_folder it should either be ('training','testing','validation') in the second parameter of function)''')\n",
        "      return None\n",
        "\n",
        "    image_box_str = storage_folder +'/'+ 'camera_box'+'/'\n",
        "    bare_image_str = storage_folder +'/'+ 'camera_image'+'/'\n",
        "    print('files_list: ', files_list)\n",
        "    for a_file in files_list:\n",
        "        if image_box_str in a_file:\n",
        "          try:\n",
        "            box_file_name = a_file\n",
        "            box_file_blob = bucket.blob(box_file_name)\n",
        "            bare_image_file_name = box_file_name.replace(image_box_str, bare_image_str)\n",
        "            bare_image_blob = bucket.blob(bare_image_file_name)\n",
        "            if bare_image_blob is not None:\n",
        "              yield box_file_blob, os.path.basename(box_file_name),bare_image_blob, os.path.basename(bare_image_file_name)\n",
        "          except:\n",
        "            continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Storing files for yolo model\n",
        "- functions to unpack and store from parquet files"
      ],
      "metadata": {
        "id": "G4lVqS4YqYRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### save path and create unique key function"
      ],
      "metadata": {
        "id": "hkq6ulNgZQpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a save path\n",
        "def create_path(file_id,store_type, images_labels = 'images'):\n",
        "  if store_type == 'train':\n",
        "    if images_labels == 'images':\n",
        "      return 'datasets/train/images/' +str(file_id) + '.jpg'\n",
        "    else:\n",
        "      return 'datasets/train/labels/' +str(file_id) + '.txt'\n",
        "\n",
        "  elif store_type == 'eval':\n",
        "    if images_labels == 'images':\n",
        "      return 'datasets/eval/images/' +str(file_id) + '.jpg'\n",
        "    else:\n",
        "      return 'datasets/eval/labels/' +str(file_id) + '.txt'\n",
        "  elif store_type == 'train':\n",
        "    if images_labels == 'images':\n",
        "      return 'datasets/train/images/' +str(file_id) + '.jpg'\n",
        "    else:\n",
        "      return 'datasets/train/labels/' +str(file_id) + '.txt'\n",
        "  else:\n",
        "    print('error type parameter: train / eval / test')\n",
        "\n",
        "# creating a key column\n",
        "def create_key_column(select_df):\n",
        "  return select_df['key.segment_context_name'].astype(str) +  select_df['key.frame_timestamp_micros'].astype(str) + select_df['key.camera_name'].astype(str)\n"
      ],
      "metadata": {
        "id": "GzLiKA0OY1ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### unpacking, scaling, storing images and annotations seperately"
      ],
      "metadata": {
        "id": "7_i3GODJY93L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constructing and saving image to path we are\n",
        "# here we are checking the image size and resizing it to 640 x 640\n",
        "def build_save_image(byte_string,image_path):\n",
        "  image_bytes = io.BytesIO(byte_string)\n",
        "  image = Image.open(image_bytes)\n",
        "  original_image_size = image.size\n",
        "  if (original_image_size[0] %32 == 0) and (original_image_size[1] %32 == 0):\n",
        "    resized_image = image.resize((640,640))\n",
        "    resized_image.save(image_path)\n",
        "    return ('success', original_image_size)\n",
        "  else:\n",
        "    return 'fail'\n",
        "\n",
        "# building bounding box labels\n",
        "# here we are also scaling the bounding box positions to the new image of 640 x 640\n",
        "def build_save_labels(df,txt_file_path,image_size):\n",
        "  width, height = image_size\n",
        "  df.loc[:,'center_x'] = (df.loc[:,'[CameraBoxComponent].box.center.x'] * (640/width))/640\n",
        "  df.loc[:,'center_y'] = (df.loc[:,'[CameraBoxComponent].box.center.y'] * (640/height))/640\n",
        "  df.loc[:,'size_x'] = (df.loc[:,'[CameraBoxComponent].box.size.x'] * (640/width))/640\n",
        "  df.loc[:,'size_y'] = (df.loc[:,'[CameraBoxComponent].box.size.y'] * (640/height))/640\n",
        "\n",
        "  select_col_df = df[['[CameraBoxComponent].type','center_x','center_y','size_x','size_y']]\n",
        "  select_col_pd = select_col_df\n",
        "  select_col_pd.to_csv(txt_file_path, sep=' ', header=False, index=False)\n",
        "  return None\n",
        "\n"
      ],
      "metadata": {
        "id": "g8iMbnDsY-UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combining all functions above\n",
        "def unpack_store_images(image_parquet,box_parquet, store_type = 'train'):\n",
        "  file_path_store = []\n",
        "  image_df = pd.read_parquet(image_parquet)\n",
        "  box_df = pd.read_parquet(box_parquet)\n",
        "\n",
        "  image_df.loc[:,'key_column'] = create_key_column(image_df)\n",
        "  box_df.loc[:,'key_column'] = create_key_column(box_df)\n",
        "\n",
        "  commmon_key_list = list(set(box_df['key_column'].tolist()) & set(image_df['key_column'].tolist()))\n",
        "  id_iterator = 0\n",
        "  for common_key in tqdm(commmon_key_list):\n",
        "    key_loc_image = image_df.loc[image_df['key_column'] == common_key]\n",
        "    image_bytes = key_loc_image.reset_index().loc[0, '[CameraImageComponent].image']\n",
        "    image_path = create_path(id_iterator,store_type, images_labels = 'images')\n",
        "\n",
        "    key_loc_box = box_df.loc[box_df['key_column'] == common_key]\n",
        "    label_path = create_path(id_iterator,store_type, images_labels = 'text')\n",
        "\n",
        "    save_confirm = build_save_image(image_bytes,image_path)\n",
        "    if save_confirm[0] == 'success':\n",
        "      # lets now complete box\n",
        "\n",
        "      build_save_labels(key_loc_box,label_path,save_confirm[1])\n",
        "\n",
        "      #lets update accumulators\n",
        "      id_iterator +=1\n",
        "      file_path_store.append(image_path)\n",
        "      file_path_store.append(label_path)\n",
        "\n",
        "  return file_path_store"
      ],
      "metadata": {
        "id": "b7YA2v812Ghv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building model"
      ],
      "metadata": {
        "id": "bBH2p3xymiUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(file_counter, prev_model_list):\n",
        "  if (file_counter == 0):\n",
        "    model_list = []\n",
        "    model_data_dict = {}\n",
        "    param_grid = {'data':[yaml_file], 'epochs' : [20],\n",
        "                  'device' : [0], 'patience' : [10],\n",
        "                  'workers' : [0],'batch': [64],\n",
        "                  'optimizer': ['SGD','Adamax'],\n",
        "                  'lr0': [0.01,0.05], 'lrf': [0.01,0.05],\n",
        "                  'momentum': [0.90,0.95], 'weight_decay': [0.0001,0.0005]}\n",
        "    grid_iterator = ParameterGrid(param_grid)\n",
        "    model_number = 0\n",
        "    for a_grid in grid_iterator:\n",
        "      model = YOLO('yolov8n.yaml')\n",
        "      model.train(data=a_grid['data'], epochs = a_grid['epochs'],device = a_grid['device'],\n",
        "                  patience = a_grid['patience'], workers = a_grid['workers'], batch = a_grid['batch'],\n",
        "                  optimizer = a_grid['optimizer'], lr0 = a_grid['lr0'],\n",
        "                  lrf = a_grid['lrf'], momentum = a_grid['momentum'], weight_decay = a_grid['weight_decay'])\n",
        "\n",
        "      model_path ='model_'+str(model_number) + '.pt'\n",
        "      model_data_dict={'parameters': a_grid,'model_path': model_path}\n",
        "\n",
        "      output_location = model.export()\n",
        "      updated_location = output_location.replace('torchscript','pt')\n",
        "      move_copy(updated_location, model_path)\n",
        "\n",
        "      model_list.append(model_data_dict)\n",
        "      model_number +=1\n",
        "\n",
        "    return model_list\n",
        "\n",
        "  else:\n",
        "      for a_model_dict in prev_model_list:\n",
        "        model = YOLO(a_model_dict['model_path'])\n",
        "        model.train(data=a_model_dict['parameters']['data'], epochs = a_model_dict['parameters']['epochs'],\n",
        "                    device = a_model_dict['parameters']['device'],patience = a_model_dict['parameters']['patience'],\n",
        "                    workers = a_model_dict['parameters']['workers'], batch = a_model_dict['parameters']['batch'],\n",
        "                    optimizer = a_model_dict['parameters']['optimizer'], lr0 = a_model_dict['parameters']['lr0'],\n",
        "                    lrf = a_model_dict['parameters']['lrf'], momentum = a_model_dict['parameters']['momentum'],\n",
        "                    weight_decay = a_model_dict['parameters']['weight_decay'])\n",
        "\n",
        "        output_location = model.export()\n",
        "        updated_location = output_location.replace('torchscript','pt')\n",
        "        delete_file([a_model_dict['model_path']])\n",
        "        move_copy(updated_location, a_model_dict['model_path'])\n",
        "      return prev_model_list\n"
      ],
      "metadata": {
        "id": "5arGsX1wmqUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating validation data"
      ],
      "metadata": {
        "id": "lHpjdrljGkTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking and then initiating GCS file download\n",
        "if file_store == 'GCS':\n",
        "  bucket, files_list = start_gcs()\n",
        "  gcs_iterator = open_gcs_file(files_list,bucket, storage_folder = 'validation')\n",
        "  file_counter = 0\n",
        "  train_file_path_list = []\n",
        "  for a_file in gcs_iterator:\n",
        "    # evaluation data\n",
        "    box_file_blob, box_file_name,bare_image_blob, bare_image_file_name = a_file\n",
        "\n",
        "    download_blob(box_file_blob,box_file_name)\n",
        "    new_box_file_name = 'box_file_'+ box_file_name\n",
        "    os.rename(box_file_name, new_box_file_name)\n",
        "\n",
        "    download_blob(bare_image_blob,bare_image_file_name)\n",
        "    new_image_file_name = 'image_file_'+ bare_image_file_name\n",
        "    os.rename(bare_image_file_name, new_image_file_name)\n",
        "\n",
        "    eval_file_path_list = unpack_store_images(new_image_file_name,new_box_file_name, store_type = 'eval')\n",
        "    delete_file([new_box_file_name,new_image_file_name])\n",
        "\n",
        "    print('completed_file_number: ',file_counter)\n",
        "    file_counter += 1\n",
        "    if (file_counter >= val_limit) and (val_limit != -1):\n",
        "      break\n",
        "\n",
        "elif file_store == 'LOCAL':\n",
        "    train_file_path_list = unpack_store_images(val_box_data_file_path,val_image_data_file_path, store_type = 'eval')\n",
        "else:\n",
        "  print('''check file_store variable, it should be in capital 'GCS' or 'LOCAL' ''')\n"
      ],
      "metadata": {
        "id": "QFtHGq_aGn_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main run to create train data store and train different hyperparam models"
      ],
      "metadata": {
        "id": "VphlxgrHyf4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking and then initiating GCS file download\n",
        "if file_store == 'GCS':\n",
        "  bucket, files_list = start_gcs()\n",
        "  gcs_iterator = open_gcs_file(files_list,bucket, storage_folder = 'training')\n",
        "  file_counter = 0\n",
        "  model_list = []\n",
        "  train_file_path_list = []\n",
        "  for a_file in gcs_iterator:\n",
        "    # train data\n",
        "      box_file_blob, box_file_name,bare_image_blob, bare_image_file_name = a_file\n",
        "\n",
        "      download_blob(box_file_blob,box_file_name)\n",
        "      new_box_file_name = 'box_file_'+ box_file_name\n",
        "      os.rename(box_file_name, new_box_file_name)\n",
        "\n",
        "      download_blob(bare_image_blob,bare_image_file_name)\n",
        "      new_image_file_name = 'image_file_'+ bare_image_file_name\n",
        "      os.rename(bare_image_file_name, new_image_file_name)\n",
        "\n",
        "      train_file_path_list = unpack_store_images(new_image_file_name,new_box_file_name, store_type = 'train')\n",
        "      model_list = train_model(file_counter, model_list)\n",
        "      print('completed_file_number: ',file_counter)\n",
        "      file_counter += 1\n",
        "\n",
        "      delete_file([new_box_file_name,new_image_file_name]+train_file_path_list)\n",
        "      if (file_counter >= train_limit) and (train_limit != -1):\n",
        "        break\n",
        "\n",
        "elif file_store == 'LOCAL':\n",
        "    file_counter = 0\n",
        "    model_list = []\n",
        "    train_file_path_list = unpack_store_images(train_box_data_file_path,train_image_data_file_path, store_type = 'train')\n",
        "    model_list = train_model(file_counter, model_list)\n",
        "    delete_file([train_box_data_file_path,train_image_data_file_path]+train_file_path_list)\n",
        "else:\n",
        "  print('''check file_store variable, it should be in capital 'GCS' or 'LOCAL' ''')\n"
      ],
      "metadata": {
        "id": "CePd2VYmgOxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation and comparison"
      ],
      "metadata": {
        "id": "Ou4B6On87oTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets get evaluation metrics in our dicts\n",
        "parameter_dict_list =[]\n",
        "for model_dict in model_list:\n",
        "  model = YOLO(model_dict['model_path'])\n",
        "  metrics = model.val(batch = 64, device\t= 'cpu')\n",
        "  map_50_95 = metrics.box.map\n",
        "  model_dict['parameters']['map_50_95'] = map_50_95\n",
        "  parameter_dict_list.append(model_dict['parameters'])"
      ],
      "metadata": {
        "id": "hElcLbaZ7z_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create a model performance dataframe\n",
        "model_eval_df = pd.DataFrame(parameter_dict_list)\n",
        "dropped_df = model_eval_df.drop(['data','device','patience','workers'],axis = 1)\n",
        "dropped_df.to_csv('yolo_hyperparameter_evaluation.csv', index=False)\n",
        "dropped_df['lr0:lrf'] = dropped_df['lr0'].astype(str) + ' : '+ dropped_df['lrf'].astype(str)\n"
      ],
      "metadata": {
        "id": "am6BwYV_Cudn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create a plot\n",
        "\n",
        "learning_rate_chart = alt.Chart(dropped_df).mark_tick(size = 25, thickness =3).encode(\n",
        "    x= alt.X('map_50_95:Q',title = 'mean_average_percision (50:95)' ),\n",
        "    y= alt.X('lr0:lrf:N',title = 'start : end (learning rate)' ),\n",
        "    color=alt.Color(\"optimizer:N\",legend=alt.Legend(title=\"Optimizer function\"))\n",
        ").properties(title='Impact of learning rate on yolo model performance', width=600,height=200\n",
        ")\n",
        "\n",
        "momentum = alt.Chart(dropped_df).mark_tick(size = 25, thickness =3).encode(\n",
        "    x= alt.X('map_50_95:Q',title = 'mean_average_percision (50:95)' ),\n",
        "    y= alt.X('momentum:N',title = 'momentum' ),\n",
        "    color=alt.Color(\"optimizer:N\",legend=None)\n",
        ").properties(title='Impact of momentum on yolo model performance', width=600,height=200 )\n",
        "\n",
        "weight_decay = alt.Chart(dropped_df).mark_tick(size = 25, thickness =3).encode(\n",
        "    x= alt.X('map_50_95:Q',title = 'mean_average_percision (50:95)' ),\n",
        "    y= alt.X('weight_decay:N',title = 'weight_decay' ),\n",
        "    color=alt.Color(\"optimizer:N\",legend=None)\n",
        ").properties(title='Impact of weight decay on yolo model performance', width=600,height=200 )\n",
        "\n",
        "evaluation_chart = (learning_rate_chart & momentum & weight_decay).configure_axisY(titleAngle=0, titleAnchor='start').configure_axis(ticks=False\n",
        ").configure_view(stroke=None)\n",
        "\n",
        "evaluation_chart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "Ras3nF1MJC1T",
        "outputId": "ea1470d4-3e03-4928-b34f-ba56fb40f555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-1787d3306bf244f8a784fd1c609a4705\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-1787d3306bf244f8a784fd1c609a4705\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-1787d3306bf244f8a784fd1c609a4705\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"stroke\": null}, \"axis\": {\"ticks\": false}, \"axisY\": {\"titleAnchor\": \"start\", \"titleAngle\": 0}}, \"vconcat\": [{\"mark\": {\"type\": \"tick\", \"size\": 25, \"thickness\": 3}, \"encoding\": {\"color\": {\"field\": \"optimizer\", \"legend\": {\"title\": \"Optimizer function\"}, \"type\": \"nominal\"}, \"x\": {\"field\": \"map_50_95\", \"title\": \"mean_average_percision (50:95)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"lr0:lrf\", \"title\": \"start : end (learning rate)\", \"type\": \"nominal\"}}, \"height\": 200, \"title\": \"Impact of learning rate on yolo model performance\", \"width\": 600}, {\"mark\": {\"type\": \"tick\", \"size\": 25, \"thickness\": 3}, \"encoding\": {\"color\": {\"field\": \"optimizer\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"map_50_95\", \"title\": \"mean_average_percision (50:95)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"momentum\", \"title\": \"momentum\", \"type\": \"nominal\"}}, \"height\": 200, \"title\": \"Impact of momentum on yolo model performance\", \"width\": 600}, {\"mark\": {\"type\": \"tick\", \"size\": 25, \"thickness\": 3}, \"encoding\": {\"color\": {\"field\": \"optimizer\", \"legend\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"map_50_95\", \"title\": \"mean_average_percision (50:95)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"weight_decay\", \"title\": \"weight_decay\", \"type\": \"nominal\"}}, \"height\": 200, \"title\": \"Impact of weight decay on yolo model performance\", \"width\": 600}], \"data\": {\"name\": \"data-455a20488774ed55c66e7e50af9c1311\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-455a20488774ed55c66e7e50af9c1311\": [{\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0025351325359895, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0024145614504163, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0079872616019802, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0064847953300419, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0024518275258813, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0031559376407862, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0038134302767985, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0082752780192372, \"lr0:lrf\": \"0.01 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0024181561425424, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.003036437785226, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0057986431546112, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0097912052850018, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.003061267758536, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0027737031850958, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0043567444617262, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.01, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0063856838637932, \"lr0:lrf\": \"0.01 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0043356474212288, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0052158039383205, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0030335253154217, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0037546106608346, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0111822476019015, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0055019799706722, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0025511294011732, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.01, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0032577672283897, \"lr0:lrf\": \"0.05 : 0.01\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0034481939835411, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0048226252458306, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.003533957747442, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.9, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0031599023062989, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0134190986036897, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"SGD\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0049785018239168, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0001, \"map_50_95\": 0.0030392019416289, \"lr0:lrf\": \"0.05 : 0.05\"}, {\"batch\": 64, \"epochs\": 20, \"lr0\": 0.05, \"lrf\": 0.05, \"momentum\": 0.95, \"optimizer\": \"Adamax\", \"weight_decay\": 0.0005, \"map_50_95\": 0.0039469095880451, \"lr0:lrf\": \"0.05 : 0.05\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.VConcatChart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selected Model Train\n",
        "- here we only train one model, based on the top. parameters identified above"
      ],
      "metadata": {
        "id": "0UD7bqZ7bj-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def updated_train_model(file_counter, prev_model_list):\n",
        "  if (file_counter == 0):\n",
        "    model_list = []\n",
        "    model_data_dict = {}\n",
        "    param_grid = {'data':[yaml_file], 'epochs' : [20],\n",
        "                  'device' : [0], 'patience' : [10],\n",
        "                  'workers' : [0],'batch': [64],\n",
        "                  'optimizer': ['SGD'],\n",
        "                  'lr0': [0.05], 'lrf': [0.05],\n",
        "                  'momentum': [0.95], 'weight_decay': [0.0001], 'pretrained' : [True]}\n",
        "    grid_iterator = ParameterGrid(param_grid)\n",
        "    model_number = 0\n",
        "    for a_grid in grid_iterator:\n",
        "      model = YOLO('yolov8n.yaml')\n",
        "      model.train(data=a_grid['data'], epochs = a_grid['epochs'],device = a_grid['device'],\n",
        "                  patience = a_grid['patience'], workers = a_grid['workers'], batch = a_grid['batch'],\n",
        "                  optimizer = a_grid['optimizer'], lr0 = a_grid['lr0'], pretrained = a_grid['pretrained'],\n",
        "                  lrf = a_grid['lrf'], momentum = a_grid['momentum'], weight_decay = a_grid['weight_decay'])\n",
        "\n",
        "      model_path ='final_model' + '.pt'\n",
        "      model_data_dict={'parameters': a_grid,'model_path': model_path}\n",
        "\n",
        "      output_location = model.export()\n",
        "      updated_location = output_location.replace('torchscript','pt')\n",
        "      move_copy(updated_location, model_path)\n",
        "\n",
        "      model_list.append(model_data_dict)\n",
        "      model_number +=1\n",
        "\n",
        "    return model_list\n",
        "\n",
        "  else:\n",
        "      for a_model_dict in prev_model_list:\n",
        "        model = YOLO(a_model_dict['model_path'])\n",
        "        model.train(data=a_model_dict['parameters']['data'], epochs = a_model_dict['parameters']['epochs'],\n",
        "                    device = a_model_dict['parameters']['device'],patience = a_model_dict['parameters']['patience'],\n",
        "                    workers = a_model_dict['parameters']['workers'], batch = a_model_dict['parameters']['batch'],\n",
        "                    optimizer = a_model_dict['parameters']['optimizer'], lr0 = a_model_dict['parameters']['lr0'],\n",
        "                    lrf = a_model_dict['parameters']['lrf'], momentum = a_model_dict['parameters']['momentum'],\n",
        "                    weight_decay = a_model_dict['parameters']['weight_decay'])\n",
        "\n",
        "        output_location = model.export()\n",
        "        updated_location = output_location.replace('torchscript','pt')\n",
        "        delete_file([a_model_dict['model_path']])\n",
        "        move_copy(updated_location, a_model_dict['model_path'])\n",
        "      return prev_model_list\n"
      ],
      "metadata": {
        "id": "eGb3EWdIbmJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# checking and then initiating GCS file download\n",
        "if file_store == 'GCS':\n",
        "  bucket, files_list = start_gcs()\n",
        "  gcs_iterator = open_gcs_file(files_list,bucket, storage_folder = 'training')\n",
        "  file_counter = 0\n",
        "  model_list = []\n",
        "  train_file_path_list = []\n",
        "  for a_file in gcs_iterator:\n",
        "    # train data\n",
        "      box_file_blob, box_file_name,bare_image_blob, bare_image_file_name = a_file\n",
        "\n",
        "      download_blob(box_file_blob,box_file_name)\n",
        "      new_box_file_name = 'box_file_'+ box_file_name\n",
        "      os.rename(box_file_name, new_box_file_name)\n",
        "\n",
        "      download_blob(bare_image_blob,bare_image_file_name)\n",
        "      new_image_file_name = 'image_file_'+ bare_image_file_name\n",
        "      os.rename(bare_image_file_name, new_image_file_name)\n",
        "\n",
        "      train_file_path_list = unpack_store_images(new_image_file_name,new_box_file_name, store_type = 'train')\n",
        "      model_list = updated_train_model(file_counter, model_list)\n",
        "      print('completed_file_number: ',file_counter)\n",
        "      file_counter += 1\n",
        "\n",
        "      delete_file([new_box_file_name,new_image_file_name]+train_file_path_list)\n",
        "      if (file_counter >= final_model_train_limit) and (final_model_train_limit != -1):\n",
        "        break\n",
        "\n",
        "elif file_store == 'LOCAL':\n",
        "    file_counter = 0\n",
        "    model_list = []\n",
        "    train_file_path_list = unpack_store_images(train_box_data_file_path,train_image_data_file_path, store_type = 'train')\n",
        "    model_list = train_model(file_counter, model_list)\n",
        "    delete_file([train_box_data_file_path,train_image_data_file_path]+train_file_path_list)\n",
        "else:\n",
        "  print('''check file_store variable, it should be in capital 'GCS' or 'LOCAL' ''')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6-TrDvuddgni"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}